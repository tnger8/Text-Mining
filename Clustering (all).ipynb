{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'content', 'date', 'tags', 'title', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('train.json') as f:\n",
    "    data1=json.load(f)\n",
    "\n",
    "data1.keys()\n",
    "#pprint(data)\n",
    "\n",
    "with open('test.json') as f:\n",
    "    data2=json.load(f)\n",
    "\n",
    "data1.keys()\n",
    "#pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  Honda is recalling the 2017 Honda Ridgeline pi...\n",
      "1  This morning, Honda issued two safety recalls ...\n",
      "2  2016 was dominated by some pretty major headli...\n",
      "3  Last week, Hyundai recalled some 5,600 crossov...\n",
      "4  Fiat Chrysler Automobiles is recalling nearly ...\n",
      "(2835, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2835, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "set=[]\n",
    "for k,v in data1['content'].items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    set.append(v)\n",
    "\n",
    "for k,v in data2['content'].items():\n",
    "    #print(k)\n",
    "    #print(v)\n",
    "    set.append(v)\n",
    "    \n",
    "df1=pd.DataFrame(set)\n",
    "print(df1.head())\n",
    "print(df1.shape)    \n",
    "    \n",
    "df1=pd.DataFrame(set)\n",
    "df1.head()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Honda is recalling the 2017 Honda Ridgeline pi...\n",
       "1       This morning, Honda issued two safety recalls ...\n",
       "2       2016 was dominated by some pretty major headli...\n",
       "3       Last week, Hyundai recalled some 5,600 crossov...\n",
       "4       Fiat Chrysler Automobiles is recalling nearly ...\n",
       "5       Hyundai is recalling more than 5,600 Tucson an...\n",
       "6       The massive, record-breaking recall of Takatas...\n",
       "7       The National Highway Traffic Safety Administra...\n",
       "8       A little over a year ago, AutoNation made a ve...\n",
       "9       Ford has issued two recalls affecting nearly 6...\n",
       "10      Nissan is recalling select 2016 Titan Diesel X...\n",
       "11      Toyota is recalling the 2011-2016 Toyota Sienn...\n",
       "12      Kia has announced a recall of the 2008 and 200...\n",
       "13      This morning, Fiat Chrysler Automobiles issued...\n",
       "14      Mazda is recalling RX-8 vehicles from the 2004...\n",
       "15      Mitsubishi is recalling roughly 195,000 U.S. v...\n",
       "16      Volvo has issued recalls for 2016 and 2017 mod...\n",
       "17      Kia is recalling the 2016 Sorento crossover to...\n",
       "18      The long, sad saga of Takata and its fatally f...\n",
       "19      BMW is recalling a wide range of cars and cros...\n",
       "20      This morning, Ford Motor Company issued three ...\n",
       "21      Subaru is recalling more than 100,000 Forester...\n",
       "22      Toyota is recalling roughly 7,100 Highlander c...\n",
       "23      Hyundai is recalling nearly 63,000 Sonata Hybr...\n",
       "24      Fiat Chrysler Automobiles is recalling 2016 an...\n",
       "25      Hyundai is recalling the 2010-2016 Genesis Cou...\n",
       "26      The beloved Honda Civic received a snazzy rede...\n",
       "27      Kia is recalling select 2016 Kia Optima sedans...\n",
       "28      Toyota is recalling select 2016 and 2017 Toyot...\n",
       "29      On Friday, Volkswagens Audi unit recalled more...\n",
       "                              ...                        \n",
       "2805    The Basics: Hyundai is recalling 41,264 2007-2...\n",
       "2806    Whether due to faulty auxiliary cable wiring i...\n",
       "2807    UPDATE: An earlier version of this article sai...\n",
       "2808    Update: We spoke with a Ford representative wh...\n",
       "2809    The Basics: Bentley is recalling just 88 2017 ...\n",
       "2810    Chrysler announced a pair of recalls for the D...\n",
       "2811    According to Reuters, Toyota has reached a set...\n",
       "2812    The Basics: BMW is recalling 136,188 vehicles ...\n",
       "2813    WASHINGTON — Kia Motors Corp said on Friday it...\n",
       "2814    Toyota issued a stop-sale order on the Prius o...\n",
       "2815    The Basics: Subaru is recalling a total of 100...\n",
       "2816    Update: This post has been updated with inform...\n",
       "2817    Audi will follow the example of Volkswagen her...\n",
       "2818    Honda and the National Highway Traffic Safety ...\n",
       "2819    The Basics: Hyundai is recalling 2015-2016 Hyu...\n",
       "2820    Fiat Chrysler just announced a pair of recalls...\n",
       "2821    The Basics: Honda is recalling about 350,000 2...\n",
       "2822    Lexus is once again taking aim at plug-in vehi...\n",
       "2823    The Basics: Toyota is recalling around 340,000...\n",
       "2824    BERLIN/FRANKFURT — German Transport Minister A...\n",
       "2825    Ford Motor Co. is already recalling the 2017 L...\n",
       "2826    The Basics: Volkswagen Group is recalling 281,...\n",
       "2827    If you own a 2011 or 2012 model-year Nissan Ve...\n",
       "2828    The Basics: Porsche is recalling roughly 243 m...\n",
       "2829    Toyota is recalling 7,600 Prius vehicles for a...\n",
       "2830    The Basics: Nissan has recalled approximately ...\n",
       "2831    The Basics: General Motors is recalling 3.64 m...\n",
       "2832    A Florida family is out a Jeep Cherokee and a ...\n",
       "2833    The Basics: Ford is expanding an existing reca...\n",
       "2834    Nissan gave a free Leaf EV to the family of si...\n",
       "Name: a, Length: 2835, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords=stopwords.words(\"English\") + ['one', 'become', 'get', 'make', 'take', 'recall','said', 'say', 'could', 'nhtsa', 'n\\'t', 'may', 'vehicle', 'car']\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[ WNlemma.lemmatize(t.lower()) for t in tokens]\n",
    "    tokens=[ t for t in tokens if t not in mystopwords]\n",
    "    tokens = [ t for t in tokens if len(t) >= 3 ]\n",
    "    text_after_process=\" \".join(tokens)\n",
    "    return(text_after_process)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_train = df1['a'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2835, 2500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tfidf matrix\n",
    "vectorizer = TfidfVectorizer(max_features=2500,\n",
    "                              stop_words=mystopwords,\n",
    "                             use_idf=True)\n",
    "X = vectorizer.fit_transform(toks_train)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SVD to reduce dimensions\n",
    "svd = TruncatedSVD(500)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_lsa = lsa.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 76%\n"
     ]
    }
   ],
   "source": [
    "# Check how much variance is explained\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 169 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=1000,\n",
       "    n_clusters=5, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the actual clustering\n",
    "from sklearn.cluster import KMeans\n",
    "#random_state=4321\n",
    "km3 = KMeans(n_clusters=5, init='k-means++', max_iter=1000, n_init=1)\n",
    "%time km3.fit(X_lsa)\n",
    "\n",
    "#‘k-means++’ : selects initial cluster centers for k-mean clustering in a smart way to speed up convergence.\n",
    "#n_init : int, default: 10. Number of time the k-means algorithm will be run with different centroid seeds.\n",
    "#Maximum number of iterations of the k-means algorithm for a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient for 3 clusters: 0.033\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "# Silhouette: more similar within clusters, more distant between clusters\n",
    "# The higher the better (-1 to 1)\n",
    "\n",
    "print(\"Silhouette Coefficient for 3 clusters: %0.3f\"\n",
    "      % metrics.silhouette_score(X_lsa, km3.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: blogsmith widget fivemin image display 2015 none postcontentcontainer cke_show_borders block\n",
      "Cluster 1: ford owner safety model chrysler brake 2014 steering seat affected\n",
      "Cluster 2: fuel tank ford pump leak engine fire owner model safety\n",
      "Cluster 3: cars com find dealer owner service local department free repair\n",
      "Cluster 4: toyota takata million honda inflator company airbag automaker lexus safety\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_terms(cm, num):\n",
    "    original_space_centroids = svd.inverse_transform(cm.cluster_centers_)\n",
    "    order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(num):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()\n",
    "\n",
    "print_terms(km3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
