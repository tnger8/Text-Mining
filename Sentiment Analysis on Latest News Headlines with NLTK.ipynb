{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on News Headlines with Python‚Äôs Natural Language Toolkit (NLTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edited By: Jia Xin\n",
    "Date : 31 Oct 2019\n",
    "    \n",
    " In this document, we aim to extract the sentiment of the archived news headliner using NLTK's Vader package. The package used Lexicon and rule based model to classify sentiment of a text into 3 classes, positive (1), negative (-1) and neutral (0). Thru this excercise, we hope to observe both the strengths and weaknesses of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required package \n",
    "\n",
    "from IPython import display\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', context='talk', palette='Dark2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is taken from a combination of kaggle, bbc, google news and reuters RSS feed. The data is saved in csv form. We load it in using pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file 'filename.csv' \n",
    "# (in the same directory that your python process is based)\n",
    "data = pd.read_csv(\"tweets1.csv\") \n",
    "#data = pd.read_csv(\"date_headline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>author</th>\n",
       "      <th>published_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meanwhile in KL.. #singapore pic.twitter.com/h...</td>\n",
       "      <td>Tawfik Daud</td>\n",
       "      <td>Sat, 08 Feb 2020 09:21:31 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read this! The #healthcare workers battling th...</td>\n",
       "      <td>Claude &amp;nbsp;üìù</td>\n",
       "      <td>Sat, 08 Feb 2020 05:07:28 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#coronavirus Update: My Worldwide Case CountJu...</td>\n",
       "      <td>IndoPacific News</td>\n",
       "      <td>Sat, 15 Feb 2020 03:03:27 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Singapore is the most infected country outsid...</td>\n",
       "      <td>Learn from Data</td>\n",
       "      <td>Tue, 11 Feb 2020 00:54:51 GMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So this is the situation at NTUC FairPrice JEM...</td>\n",
       "      <td>Amz‚Å∑</td>\n",
       "      <td>Sat, 08 Feb 2020 00:55:14 GMT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content            author  \\\n",
       "0  Meanwhile in KL.. #singapore pic.twitter.com/h...       Tawfik Daud   \n",
       "1  Read this! The #healthcare workers battling th...    Claude &nbsp;üìù   \n",
       "2  #coronavirus Update: My Worldwide Case CountJu...  IndoPacific News   \n",
       "3  #Singapore is the most infected country outsid...   Learn from Data   \n",
       "4  So this is the situation at NTUC FairPrice JEM...              Amz‚Å∑   \n",
       "\n",
       "                  published_date  \n",
       "0  Sat, 08 Feb 2020 09:21:31 GMT  \n",
       "1  Sat, 08 Feb 2020 05:07:28 GMT  \n",
       "2  Sat, 15 Feb 2020 03:03:27 GMT  \n",
       "3  Tue, 11 Feb 2020 00:54:51 GMT  \n",
       "4  Sat, 08 Feb 2020 00:55:14 GMT  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the first 5 lines of the loaded data \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import nltk vader = sentiment intensity analyser. This function enable us to quickly determine the general sentiment of a text. There is no aspect mining involved, and it is soley built using lexicon and rule based model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Content': 'Meanwhile in KL.. #singapore pic.twitter.com/h5vO4PVi0r',\n",
      "  'compound': 0.0,\n",
      "  'neg': 0.0,\n",
      "  'neu': 1.0,\n",
      "  'pos': 0.0},\n",
      " {'Content': 'Read this! The #healthcare workers battling the #coronavirus on the frontline are '\n",
      "             'HUMANS too! They deserved our utmost respect & not ostracised by the society. '\n",
      "             '#coronavirussingapore #Singapore #Thoughts pic.twitter.com/nM6I3qmQdq',\n",
      "  'compound': 0.3786,\n",
      "  'neg': 0.066,\n",
      "  'neu': 0.818,\n",
      "  'pos': 0.116},\n",
      " {'Content': '#coronavirus Update: My Worldwide Case CountJust updated: New cases in #Japan, '\n",
      "             '#Singapore & #EgyptMany new cases & deaths in #ChinaNote: #China is likely '\n",
      "             'downplaying the numbers#WuhanCoronavirus  #CoronavirusOutbreak#COVID19   '\n",
      "             '#WuhanPneumonia pic.twitter.com/qnS14B4vEI',\n",
      "  'compound': 0.0,\n",
      "  'neg': 0.0,\n",
      "  'neu': 1.0,\n",
      "  'pos': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()\n",
    "results = []\n",
    "\n",
    "for line in data['Content']:\n",
    "    pol_score = sia.polarity_scores(line)\n",
    "    pol_score['Content'] = line\n",
    "    results.append(pol_score)\n",
    "\n",
    "pprint(results[:3], width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not really a fan of him as a politician, per se. But as a ninety-four-years-old human being, Tun Mahathir is just amazingly exceptional.This is the very same man during his graduation at King Edward VII College of Medicine Singapore, 67 years ago. https://t.co/MHanJSYCZE pic.twitter.com/OdDzE8XMZv'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Meanwhile in KL.. #singapore pic.twitter.com/h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>Read this! The #healthcare workers battling th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>#coronavirus Update: My Worldwide Case CountJu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5413</td>\n",
       "      <td>#Singapore is the most infected country outsid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>So this is the situation at NTUC FairPrice JEM...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound  \\\n",
       "0  0.000  1.000  0.000    0.0000   \n",
       "1  0.066  0.818  0.116    0.3786   \n",
       "2  0.000  1.000  0.000    0.0000   \n",
       "3  0.132  0.868  0.000   -0.5413   \n",
       "4  0.032  0.873  0.095    0.5267   \n",
       "\n",
       "                                             Content  \n",
       "0  Meanwhile in KL.. #singapore pic.twitter.com/h...  \n",
       "1  Read this! The #healthcare workers battling th...  \n",
       "2  #coronavirus Update: My Worldwide Case CountJu...  \n",
       "3  #Singapore is the most infected country outsid...  \n",
       "4  So this is the situation at NTUC FairPrice JEM...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>Content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Meanwhile in KL.. #singapore pic.twitter.com/h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.3786</td>\n",
       "      <td>Read this! The #healthcare workers battling th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>#coronavirus Update: My Worldwide Case CountJu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5413</td>\n",
       "      <td>#Singapore is the most infected country outsid...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>So this is the situation at NTUC FairPrice JEM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound  \\\n",
       "0  0.000  1.000  0.000    0.0000   \n",
       "1  0.066  0.818  0.116    0.3786   \n",
       "2  0.000  1.000  0.000    0.0000   \n",
       "3  0.132  0.868  0.000   -0.5413   \n",
       "4  0.032  0.873  0.095    0.5267   \n",
       "\n",
       "                                             Content  label  \n",
       "0  Meanwhile in KL.. #singapore pic.twitter.com/h...      0  \n",
       "1  Read this! The #healthcare workers battling th...      1  \n",
       "2  #coronavirus Update: My Worldwide Case CountJu...      0  \n",
       "3  #Singapore is the most infected country outsid...     -1  \n",
       "4  So this is the situation at NTUC FairPrice JEM...      1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Content', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df[['Content', 'label', 'compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>label</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meanwhile in KL.. #singapore pic.twitter.com/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Read this! The #healthcare workers battling th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#coronavirus Update: My Worldwide Case CountJu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Singapore is the most infected country outsid...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.5413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So this is the situation at NTUC FairPrice JEM...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Why are all the people so kiasu go and sweep a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why condoms also sold out in Singapore? üòÇ #sin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is the correct way to dispose your used m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Some kind soul has been giving away masks and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Check out this ‚ÄúPolite‚Äù baggage system at Chan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#Singapore becomes 2nd most infected country o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.5413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What the Orange alert level on DORSCON means #...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>So high the level of wayang#Singapore #PAP #Wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Welcome to #Singapore!üò¢üò≥üò±#coronavirus #covid19...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10 v 1 fight at Cuppage Plaza KTV! Rabak sia! ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.4912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Living in SG means everyday commute is sightin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>If you'd like another example of the ridiculou...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I hope twitter can do it‚Äôs thing and spread th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>At least sixteen #coronavirus cases linked to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>This the most amazing thing I've ever seen in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>This is so very sad &amp; heartbreaking! Some of t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>China still concealing the truth of #WuhanViru...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CORONAVIRUS: ‚ÄúAll the crematoriums of Hubei ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20,000 ducks &amp; 30,000 geese that I know of hav...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.8176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5 nowych przypadk√≥w #WuhanVirus w Japonii.5 ne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Infekcja koronawirusem #WuhanVirus  potwierdzo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70 nowych przypadk√≥w #WuhanVirus  w Japonii. Z...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1 nowy przypadek #WuhanVirus w Japonii. Wed≈Çug...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.8020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Po≈Çudniowa Korea zg≈Çasza 1 nowy przypadek #Wuh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Wszystkie drogi dojazdowe do Wuhan zosta≈Çy zni...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>#CCPChina cop telling this #China woman to apo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>A man in his 40s in Gyeongju, #SouthKorea was ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>????????,???????????????????????????????????,?...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>#China The end of ppl who don't wear a mask--b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>ULTIMA HORA: Hay un paciente en el Hospital Au...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Chart comparando los √∫ltimos outbreaks de viru...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>Health officials in China have published the f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>How do you greet people in #COVID?19 times? Wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>FBI orders $40,000 worth of masks and hand san...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Yes... the Iranian regime has been lying, and ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.7491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Volunteer Victoria is showing off the food don...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Communist in Uyghur Region are truly treachero...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>This guy has nailed it on #covid19 Governments...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>#SouthKorea reports 123 more cases of new #cor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Seriously. Have you seen this? #COVID?19 #COVI...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>Where the world stands today, although already...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>Is treatment of #COVID?19 possible?YESAccordin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>It is possible that the spanish flu originate ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>Bats are known to carry many diseases and coro...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>Get ready for the same thing in USA as CDC gui...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>#COVID19 growth of cases outside China.  If (*...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>If we want to stop the spread of COVID-19 aka ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>Italy now largest EU country with #WuhanCorona...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>.@foreignoffice has changed travel advice for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>Fears of a global coronavirus pandemic as case...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>That's a game changer, means the possibility o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Iran shuts schools, multiple venues as #corona...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.6557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>A new suspected #coronavirus case in Ankara, T...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>Oh god...I am not want share this but...A lot ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Not really a fan of him as a politician, per s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content  label  compound\n",
       "0    Meanwhile in KL.. #singapore pic.twitter.com/h...      0    0.0000\n",
       "1    Read this! The #healthcare workers battling th...      1    0.3786\n",
       "2    #coronavirus Update: My Worldwide Case CountJu...      0    0.0000\n",
       "3    #Singapore is the most infected country outsid...     -1   -0.5413\n",
       "4    So this is the situation at NTUC FairPrice JEM...      1    0.5267\n",
       "..                                                 ...    ...       ...\n",
       "633  That's a game changer, means the possibility o...      1    0.3724\n",
       "634  Iran shuts schools, multiple venues as #corona...     -1   -0.6557\n",
       "635  A new suspected #coronavirus case in Ankara, T...     -1   -0.2263\n",
       "636  Oh god...I am not want share this but...A lot ...     -1   -0.2755\n",
       "637  Not really a fan of him as a politician, per s...      1    0.3804\n",
       "\n",
       "[638 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('tweets_labels2.csv', mode='a', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    288\n",
       "-1    186\n",
       " 1    164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive headlines:\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'headline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-69143aabd623>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Positive headlines:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheadline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nNegative headlines:\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheadline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\65848\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5179\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5180\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'headline'"
     ]
    }
   ],
   "source": [
    "print(\"Positive headlines:\\n\")\n",
    "pprint(list(df[df['label'] == 1].headline)[:5], width=200)\n",
    "\n",
    "print(\"\\nNegative headlines:\\n\")\n",
    "pprint(list(df[df['label'] == -1].headline)[:5], width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "counts = df.label.value_counts(normalize=True) * 100\n",
    "\n",
    "sns.barplot(x=counts.index, y=counts, ax=ax)\n",
    "\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'])\n",
    "ax.set_ylabel(\"Percentage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "\n",
    "example = \"This is an example sentence! However, it isn't a very informative one\"\n",
    "\n",
    "print(word_tokenize(example, language='english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "print(tokenizer.tokenize(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(headlines):\n",
    "    tokens = []\n",
    "    for line in headlines:\n",
    "        line = line.lower()\n",
    "        toks = tokenizer.tokenize(line)\n",
    "        toks = [t for t in toks if t not in stop_words]\n",
    "        tokens.extend(toks)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_lines = list(df[df.label == 1].headline)\n",
    "\n",
    "pos_tokens = process_text(pos_lines)\n",
    "pos_freq = nltk.FreqDist(pos_tokens)\n",
    "\n",
    "pos_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = [x[1] for x in pos_freq.most_common()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(y_val)\n",
    "\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Word Frequency Distribution (Positive)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = []\n",
    "for i, k, z, t in zip(y_val[0::4], y_val[1::4], y_val[2::4], y_val[3::4]):\n",
    "    y_final.append(math.log(i + k + z + t))\n",
    "\n",
    "x_val = [math.log(i + 1) for i in range(len(y_final))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.xlabel(\"Words (Log)\")\n",
    "plt.ylabel(\"Frequency (Log)\")\n",
    "plt.title(\"Word Frequency Distribution (Positive)\")\n",
    "plt.plot(x_val, y_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the chart above we can observe that generally its follows the Ziph's law. \n",
    "Link:  https://www.nature.com/articles/srep12209\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_lines = list(df2[df2.label == -1].headline)\n",
    "\n",
    "neg_tokens = process_text(neg_lines)\n",
    "neg_freq = nltk.FreqDist(neg_tokens)\n",
    "\n",
    "neg_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = [x[1] for x in neg_freq.most_common()]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.plot(y_val)\n",
    "\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Word Frequency Distribution (Negative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = []\n",
    "for i, k, z in zip(y_val[0::3], y_val[1::3], y_val[2::3]):\n",
    "    if i + k + z == 0:\n",
    "        break\n",
    "    y_final.append(math.log(i + k + z))\n",
    "\n",
    "x_val = [math.log(i+1) for i in range(len(y_final))]\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.xlabel(\"Words (Log)\")\n",
    "plt.ylabel(\"Frequency (Log)\")\n",
    "plt.title(\"Word Frequency Distribution (Negative)\")\n",
    "plt.plot(x_val, y_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this command to analyse individual sentence\n",
    "\n",
    "sia.polarity_scores(\"The phone is super cool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this command to analyse individual sentence\n",
    "\n",
    "sia.polarity_scores(\"The phone is super cool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use this command to analyse individual sentence\n",
    "\n",
    "sia.polarity_scores(\"The phone is SUPER COOL!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sentiment with conjuections\n",
    "\n",
    "sia.polarity_scores(\"He is a great guy but I don't like him\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing sentiment with conjuections\n",
    "\n",
    "sia.polarity_scores(\"This phone is good but the video recorder sucks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation for Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv('reuter_headlines_labels1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters, numbers, punctuations\n",
    "train['headline'] = train['headline'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation \n",
    "tokenized_line = train['headline'].apply(lambda x: x.split())\n",
    "tokenized_line.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code below, we will study the word cloud for negative and postive sentiment texts. Before we could do any word cloud, we are required to tokenise, quick clean and remove stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in train['headline']])\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words =' '.join([text for text in train['headline'][train['label'] == -1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(neg_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "comment_words = ' '\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normal_words =' '.join([text for text in train['headline'][train['label'] == 1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, background_color ='white', stopwords = stopwords, random_state=21, max_font_size=110).generate(normal_words)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordnlp.server import CoreNLPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Trump faces severe suburban slump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
